{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submmit fasta file to the TACOS (Cell Type: HELA)\n",
    "    (https://balalab-skku.org/TACOS/) \n",
    "    You can get the prediction (Halo-seq_lncRNA_TACOS_predict.txt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "###  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python\n",
    "# To evaluate performance of TACOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate performance of model\n",
    "def evaluate_performance(y_test, y_pred, y_prob):\n",
    "    # AUROC\n",
    "    auroc = metrics.roc_auc_score(y_test,y_prob)\n",
    "    auroc_curve = metrics.roc_curve(y_test, y_prob)\n",
    "    # AUPRC\n",
    "    auprc=metrics.average_precision_score(y_test, y_prob) \n",
    "    auprc_curve=metrics.precision_recall_curve(y_test, y_prob)\n",
    "    #Accuracy\n",
    "    accuracy=metrics.accuracy_score(y_test,y_pred) \n",
    "    #MCC\n",
    "    mcc=metrics.matthews_corrcoef(y_test,y_pred)\n",
    "    \n",
    "    recall=metrics.recall_score(y_test, y_pred)\n",
    "    precision=metrics.precision_score(y_test, y_pred)\n",
    "    f1=metrics.f1_score(y_test, y_pred)\n",
    "    class_report=metrics.classification_report(y_test, y_pred,target_names = [\"control\",\"case\"])\n",
    "\n",
    "    model_perf = {\"auroc\":auroc,\"auroc_curve\":auroc_curve,\n",
    "                  \"auprc\":auprc,\"auprc_curve\":auprc_curve,\n",
    "                  \"accuracy\":accuracy, \"mcc\": mcc,\n",
    "                  \"recall\":recall,\"precision\":precision,\"f1\":f1,\n",
    "                  \"class_report\":class_report}\n",
    "        \n",
    "    return model_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output result of evaluation\n",
    "def eval_output(model_perf,path):\n",
    "    with open(os.path.join(path,\"Evaluate_Result_Halo_seq.txt\"),'w') as f:\n",
    "        f.write(\"AUROC=%s\\tAUPRC=%s\\tAccuracy=%s\\tMCC=%s\\tRecall=%s\\tPrecision=%s\\tf1_score=%s\\n\" %\n",
    "               (model_perf[\"auroc\"],model_perf[\"auprc\"],model_perf[\"accuracy\"],model_perf[\"mcc\"],model_perf[\"recall\"],model_perf[\"precision\"],model_perf[\"f1\"]))\n",
    "        f.write(\"\\n######NOTE#######\\n\")\n",
    "        f.write(\"#According to help_documentation of sklearn.metrics.classification_report:in binary classification, recall of the positive class is also known as sensitivity; recall of the negative class is specificity#\\n\\n\")\n",
    "        f.write(model_perf[\"class_report\"])\n",
    "    \n",
    "    roc_auc = model_perf[\"auroc\"]\n",
    "    # AUROC info\n",
    "    fpr,tpr,threshold = model_perf[\"auroc_curve\"]\n",
    "    #return AUROC info\n",
    "    temp_df = pd.DataFrame({\"FPR\":fpr,\"TPR\":tpr})\n",
    "    temp_df.to_csv(os.path.join(path,\"AUROC_info.txt\"),header = True,index = False, sep = '\\t')\n",
    "    \n",
    "    prc_auc = model_perf[\"auprc\"]\n",
    "    precision,recall,prc_threshod = model_perf[\"auprc_curve\"]\n",
    "    #return AUPRC info\n",
    "    temp_df_2 = pd.DataFrame({\"Recall\":recall,\"Precision\":precision})\n",
    "    temp_df_2.to_csv(os.path.join(path,\"AUPRC_info.txt\"),header = True,index = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = pd.read_csv(\"./Halo-seq_lncRNA_TACOS_predict.txt\")\n",
    "\n",
    "input_file[\"ensemble_transcript_id\"],input_file[\"True_Label\"] = input_file['Name'].str.split('_',1).str\n",
    "class_mapping = {'Nucleus': 1,'Cytoplasm': 0}\n",
    "input_file[\"Pre_Label\"] = input_file[\"Location\"].map(class_mapping)\n",
    "input_file[\"Cyto_Score\"] = input_file[\"Probability\"]\n",
    "input_file[\"Nuc_Score\"] = 1 - input_file[\"Cyto_Score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = input_file.iloc[:,3:8]\n",
    "outcome[[\"True_Label\"]] = outcome[[\"True_Label\"]].astype(int)\n",
    "outcome[[\"Pre_Label\"]] = outcome[[\"Pre_Label\"]].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output performance of lncLocator\n",
    "path = \"./Evaluation_Result\"\n",
    "if not (os.path.exists(path)):\n",
    "    os.mkdir(path)\n",
    "model_perf = evaluate_performance(outcome[\"True_Label\"],outcome[\"Pre_Label\"],outcome[\"Nuc_Score\"])\n",
    "eval_output(model_perf,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/picb/rnomics3/yuanguohua/anaconda3/envs/pytorch/lib/python3.6/site-packages/pandas/core/frame.py:3027: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "outcome_df = outcome.iloc[:,[0,1,2]]\n",
    "outcome_df.rename(columns={\"True_Label\":\"tag\",\"Pre_Label\":\"predict_label\"},inplace = True)\n",
    "outcome_df.to_csv(os.path.join(path,\"lncRNA_sublocation_Halo_seq_TACOS_predict.tsv\"),sep = '\\t',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
