AUROC=0.7122248640832047	AUPRC=0.7292395025665971	Accuracy=0.6548089591567853	MCC=0.30776719969836197	Recall=0.7022900763358778	Precision=0.6555819477434679	f1_score=0.6781326781326782

######NOTE#######
#According to help_documentation of sklearn.metrics.classification_report:in binary classification, recall of the positive class is also known as sensitivity; recall of the negative class is specificity#

              precision    recall  f1-score   support

     control       0.65      0.60      0.63       366
        case       0.66      0.70      0.68       393

    accuracy                           0.65       759
   macro avg       0.65      0.65      0.65       759
weighted avg       0.65      0.65      0.65       759
