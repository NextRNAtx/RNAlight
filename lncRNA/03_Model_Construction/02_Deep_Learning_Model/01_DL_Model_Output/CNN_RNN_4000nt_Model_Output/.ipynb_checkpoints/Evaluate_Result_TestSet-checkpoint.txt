AUROC=0.7091559449866904	AUPRC=0.7240268710312815	Accuracy=0.6526315789473685	MCC=0.3050998082703451	Recall=0.6530612244897959	Precision=0.6666666666666666	f1_score=0.6597938144329897

######NOTE#######
#According to help_documentation of sklearn.metrics.classification_report:in binary classification, recall of the positive class is also known as sensitivity; recall of the negative class is specificity#

              precision    recall  f1-score   support

     control       0.64      0.65      0.65       184
        case       0.67      0.65      0.66       196

   micro avg       0.65      0.65      0.65       380
   macro avg       0.65      0.65      0.65       380
weighted avg       0.65      0.65      0.65       380
