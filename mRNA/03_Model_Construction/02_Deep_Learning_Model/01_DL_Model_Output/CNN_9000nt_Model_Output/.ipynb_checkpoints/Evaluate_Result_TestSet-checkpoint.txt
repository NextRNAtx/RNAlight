AUROC=0.7086963097398669	AUPRC=0.6413908746016295	Accuracy=0.6602316602316602	MCC=0.3003228365828087	Recall=0.5087719298245614	Precision=0.6444444444444445	f1_score=0.5686274509803921

######NOTE#######
#According to help_documentation of sklearn.metrics.classification_report:in binary classification, recall of the positive class is also known as sensitivity; recall of the negative class is specificity#

              precision    recall  f1-score   support

     control       0.67      0.78      0.72       290
        case       0.64      0.51      0.57       228

   micro avg       0.66      0.66      0.66       518
   macro avg       0.66      0.64      0.64       518
weighted avg       0.66      0.66      0.65       518
