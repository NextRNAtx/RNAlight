AUROC=0.6813974591651543	AUPRC=0.6514203960515229	Accuracy=0.6332046332046332	MCC=0.24035395191032055	Recall=0.4298245614035088	Precision=0.620253164556962	f1_score=0.5077720207253886

######NOTE#######
#According to help_documentation of sklearn.metrics.classification_report:in binary classification, recall of the positive class is also known as sensitivity; recall of the negative class is specificity#

              precision    recall  f1-score   support

     control       0.64      0.79      0.71       290
        case       0.62      0.43      0.51       228

   micro avg       0.63      0.63      0.63       518
   macro avg       0.63      0.61      0.61       518
weighted avg       0.63      0.63      0.62       518
