AUROC=0.7252268602540834	AUPRC=0.6512185158813966	Accuracy=0.6698841698841699	MCC=0.3230891872910105	Recall=0.5614035087719298	Precision=0.6432160804020101	f1_score=0.5995316159250585

######NOTE#######
#According to help_documentation of sklearn.metrics.classification_report:in binary classification, recall of the positive class is also known as sensitivity; recall of the negative class is specificity#

              precision    recall  f1-score   support

     control       0.69      0.76      0.72       290
        case       0.64      0.56      0.60       228

    accuracy                           0.67       518
   macro avg       0.66      0.66      0.66       518
weighted avg       0.67      0.67      0.67       518
